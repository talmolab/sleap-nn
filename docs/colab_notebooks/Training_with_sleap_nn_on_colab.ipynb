{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "o3hJ2wtS4iUq",
    "3FzIWsGRCcuJ",
    "X5k2TSbgC3sJ"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": "<a href=\"https://colab.research.google.com/github/talmolab/sleap-nn/blob/main/docs/colab_notebooks/Training_with_sleap_nn_on_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This tutorial notebook walks through running training, inference, and evaluation worlflows in sleap-nn using higher-level APIs. (See [docs](https://nn.sleap.ai/latest/) for details on how to use our CLI).\n",
    "\n",
    "**Note**:\n",
    "Ensure you enable GPU runtime before you start tranining! Go to Runtime -> Change Runtime type -> Select \"T4 GPU\""
   ],
   "metadata": {
    "id": "bCx-YkyA32Ak"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install sleap-nn"
   ],
   "metadata": {
    "id": "qDpvJei73-Sw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjqMbPMt1EIh"
   },
   "outputs": [],
   "source": [
    "# !pip install sleap-nn[torch] --index-url https://pypi.org/simple --extra-index-url https://download.pytorch.org/whl/cu128\n",
    "\n",
    "# install from git until 0.0.6 is out!\n",
    "!pip install \"sleap-nn[torch] @ git+https://github.com/talmolab/sleap-nn.git\" --index-url https://pypi.org/simple --extra-index-url https://download.pytorch.org/whl/cu128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the previous cell returns `False`, check if enabled GPU runtime in the Runtime settings"
   ],
   "metadata": {
    "id": "tliML5hu4XId"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "id": "CJYUFRUI5IZe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "\n",
    "import sleap_io as sio\n",
    "from sleap_nn.train import run_training\n",
    "from sleap_nn.config.training_job_config import TrainingJobConfig\n",
    "from sleap_nn.predict import run_inference\n",
    "from sleap_nn.evaluation import Evaluator\n",
    "\n"
   ],
   "metadata": {
    "id": "xVSIJDtb5KDO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Verify installation\n",
    "\n",
    "sleap_nn.__version__"
   ],
   "metadata": {
    "id": "ForJMj4P5R3T"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Check if cuda is available\n",
    "\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "id": "lAf6cxm45TXM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Settin up"
   ],
   "metadata": {
    "id": "o3hJ2wtS4iUq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_labels_paths = [\"/path/to/train/slp/file\"]\n",
    "val_labels_paths = [\"/path/to/val/slp/file\"] # set this to `None` if you don't have a validation dataset\n",
    "test_file_path = \"path/to/test/file\" # set this to `None` if you dont have a test file"
   ],
   "metadata": {
    "id": "njdyHEaP4WNd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you have an `yaml` config file, load it using the below command (check the [docs](https://nn.sleap.ai/latest/config/) for config format / to download sample configs):"
   ],
   "metadata": {
    "id": "L0GlDWLI5DZj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "config = OmegaConf.load(\"/path/to/config/file.yaml\")\n",
    "\n",
    "# if you have a `json` config file from SLEAP <= v1.4, then use the below code to get the `sleap-nn` config\n",
    "# config = TrainingJobConfig.load_sleap_config(\"path/to/config.json\")"
   ],
   "metadata": {
    "id": "cF-NUAPj48x_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Set the train, val and test file paths\n",
    "\n",
    "config.data_config.train_labels_path = train_labels_paths\n",
    "config.data_config.val_labels_path = val_labels_path # set this to `None` if you don't have a validation dataset\n",
    "config.data_config.test_file_path = test_file_path # set this to `None` if you dont have a test file"
   ],
   "metadata": {
    "id": "2XZAN7NG6JqC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# To speed up training:\n",
    "\n",
    "# config.data_config.data_pipeline_fw = \"torch_dataset_cache_img_memory\""
   ],
   "metadata": {
    "id": "ZLi1Jmn66f9_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# set-up the ckpt dir and run names\n",
    "\n",
    "config.trainer_config.ckpt_dir = \"path/to/ckpt/dir\"\n",
    "config.trainer_config.run_name = None # if None, a name with the timestamp and model type would be assigned\n",
    "\n",
    "config.trainer_config.max_epochs = 100\n",
    "\n",
    "config.trainer_config.train_data_loader.num_workers = 2\n",
    "config.trainer_config.val_data_loader.num_workers = 2"
   ],
   "metadata": {
    "id": "3tvGEHB56kBU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# for finetuning (initializing model with prv trained ckpts)\n",
    "\n",
    "# If previous model ckpts from SLEAP >= v1.5\n",
    "# model_ckpt_file_path = (Path(prv_model_ckpt_dir_path) / \"best.ckpt\").as_posix()\n",
    "\n",
    "# If previous model ckpts from SLEAP < v1.5\n",
    "# model_ckpt_file_path = (Path(prv_model_ckpt_dir_path) / \"best_model.h5\").as_posix()\n",
    "\n",
    "# config.model_config.pretrained_backbone_weights = model_ckpt_file_path\n",
    "# config.model_config.pretrained_head_weights = model_ckpt_file_path"
   ],
   "metadata": {
    "id": "AIwJv-sKEUUR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# to setup wandb\n",
    "\n",
    "# config.trainer_config.use_wandb = True\n",
    "# config.trainer_config.wandb.entity = \"<wandb entity name>\"\n",
    "# config.trainer_config.wandb.project = \"<wandb project name>\"\n",
    "# config.trainer_config.wandb.name =  \"<wandb run name>\"\n",
    "# config.trainer_config.wandb.save_viz_imgs_wandb = False\n",
    "# config.trainer_config.wandb.api_key = \"<wandb API key>\" # this is required to login to your account\n",
    "# config.trainer_config.wandb.group = \"<wandb run group name>\""
   ],
   "metadata": {
    "id": "-RkUm21BAmdv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check the config and update any parameters (if needed)!\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "OEmKim-0CV6C"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(OmegaConf.to_yaml(config, resolve=True, sort_keys=False))"
   ],
   "metadata": {
    "id": "n2wAnPyoCU29"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "id": "3FzIWsGRCcuJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# if you have custom train and val labels object, then you could pass them to the `run_training()` function\n",
    "# Note that these labels will override the labels path provided in the config\n",
    "\n",
    "# run_training(config, train_labels=[train_labels], val_labels=[val_labels])"
   ],
   "metadata": {
    "id": "p5lW9mR0CkwJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "run_training(config)"
   ],
   "metadata": {
    "id": "AK4gDpzRCVqz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running inference"
   ],
   "metadata": {
    "id": "X5k2TSbgC3sJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the training is completed and we have the ckpts, we can run inference on either a `.slp` file or a `.mp4` with the trained model."
   ],
   "metadata": {
    "id": "vu4xmiHeC5LI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pred_labels = run_inference(\n",
    "    data_path=\"path/to/inference/file\",\n",
    "    model_paths=[\"path/to/ckpt/dir/run_name\"],\n",
    "    output_path=f\"predictions_{model_trainer.model_type}.slp\",\n",
    ")"
   ],
   "metadata": {
    "id": "LGHYyeAuC4or"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate the model against ground truth and compute metrics. (Make sure gt_labels contains ground-truth annotations.)"
   ],
   "metadata": {
    "id": "4tG0otYDDM63"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#### NOTE: only if you have Ground-truth data\n",
    "\n",
    "gt_labels = sio.load_slp(path_to_val_slp_file)\n",
    "\n",
    "evaluator = Evaluator(\n",
    "    ground_truth_instances=gt_labels,\n",
    "    predicted_instances=pred_labels,\n",
    ")\n",
    "\n",
    "metrics = evaluator.evaluate()\n",
    "\n",
    "print(f\"Evaluation metrics:\")\n",
    "print(f\"OKS mAP: {metrics['voc_metrics']['oks_voc.mAP']}\")\n",
    "print(f\"Dist p90: {metrics['distance_metrics']['p90']}\")"
   ],
   "metadata": {
    "id": "GW9vIUMTDNUp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's visualize the predictions!"
   ],
   "metadata": {
    "id": "6liVrDRMDezO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import sleap_io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_preds(gt_labels, pred_labels, lf_index):\n",
    "    _fig, _ax = plt.subplots(1, 1, figsize=(5 * 1, 5 * 1))\n",
    "\n",
    "    # Plot each frame\n",
    "    if gt_labels is not None:\n",
    "      gt_lf = gt_labels[lf_index]\n",
    "    pred_lf = pred_labels[lf_index]\n",
    "\n",
    "    # Ensure we're plotting keypoints for the same frame\n",
    "    if gt_labels is not None:\n",
    "      assert (\n",
    "          gt_lf.frame_idx == pred_lf.frame_idx\n",
    "      ), f\"Frame mismatch at {lf_index}: GT={gt_lf.frame_idx}, Pred={pred_lf.frame_idx}\"\n",
    "\n",
    "    _ax.imshow(gt_lf.image, cmap=\"gray\")\n",
    "    _ax.set_title(\n",
    "        f\"Frame {gt_lf.frame_idx} (lf idx: {lf_index})\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "\n",
    "    if gt_labels is not None:\n",
    "      # Plot ground truth instances\n",
    "      for idx, instance in enumerate(gt_lf.instances):\n",
    "          if not instance.is_empty:\n",
    "              gt_pts = instance.numpy()\n",
    "              _ax.plot(\n",
    "                  gt_pts[:, 0],\n",
    "                  gt_pts[:, 1],\n",
    "                  \"go\",\n",
    "                  markersize=6,\n",
    "                  alpha=0.8,\n",
    "                  label=\"GT\" if idx == 0 else \"\",\n",
    "              )\n",
    "\n",
    "    # Plot predicted instances\n",
    "    for idx, instance in enumerate(pred_lf.instances):\n",
    "        if not instance.is_empty:\n",
    "            pred_pts = instance.numpy()\n",
    "            _ax.plot(\n",
    "                pred_pts[:, 0],\n",
    "                pred_pts[:, 1],\n",
    "                \"rx\",\n",
    "                markersize=6,\n",
    "                alpha=0.8,\n",
    "                label=\"Pred\" if idx == 0 else \"\",\n",
    "            )\n",
    "\n",
    "    # Add legend\n",
    "    _ax.legend(loc=\"upper right\", fontsize=8)\n",
    "\n",
    "    _ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(f\"Predictions\", fontsize=16, fontweight=\"bold\", y=0.98)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return"
   ],
   "metadata": {
    "id": "yF6nF9CxDO9b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "frame_index_to_view = 9\n",
    "gt_labels = sio.load_slp(\"path/to/gt.slp\") # set to None if there are no ground-truth labels\n",
    "plot_preds(gt_labels, pred_labels, lf_index=frame_index_to_view)"
   ],
   "metadata": {
    "id": "QGb_abPQDaug"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}