data_config:
  provider: LabelsReader
  pipeline: TopdownConfmaps
  train:
    labels_path: "minimal_instance.pkg.slp"
    preprocessing:
      max_width: 
      max_height: 
      scale: 1.0
      is_rgb: False
      crop_hw:
        - 160
        - 160
    use_augmentations: true
    augmentation_config:
      geometric:
        rotation: 180.0
        scale: 0
        translate_width: 0
        translate_height: 0
        affine_p: 0.5
  val:
    labels_path: "minimal_instance.pkg.slp"
    preprocessing:
      max_width: 
      max_height: 
      is_rgb: False
      scale: 1.0
      crop_hw:
        - 160
        - 160
    use_augmentations: false
model_config:
  init_weights: xavier
  pre_trained_weights:
  backbone_config:
    backbone_type: unet
    backbone_config:
        in_channels: 1
        kernel_size: 3
        filters: 16
        filters_rate: 2
        max_stride: 16
        convs_per_block: 2
        stacks: 1
        stem_stride: 
        middle_block: True
        up_interpolate: True
  
  # pre_trained_weights: ConvNeXt_Tiny_Weights
  # backbone_config:
  #   backbone_type: convnext
  #   backbone_config:
  #     in_channels: 1
  #     model_type: tiny
  #     arch: 
  #     kernel_size: 3
  #     filters_rate: 2
  #     convs_per_block: 2
  #     up_interpolate: True
  #     stem_patch_kernel: 4
  #     stem_patch_stride: 2

  # pre_trained_weights: Swin_T_Weights
  # backbone_config:
  #   backbone_type: swint
  #   backbone_config:
  #     in_channels: 1
  #     model_type: tiny
  #     arch: 
  #     patch_size: [4,4]
  #     window_size: [7,7]
  #     kernel_size: 3
  #     filters_rate: 2
  #     convs_per_block: 2
  #     up_interpolate: True
  #     stem_patch_stride: 2

  head_configs: 
    confmaps:
        head_type: CenteredInstanceConfmapsHead
        head_config:
          part_names: None
          anchor_part: 0
          sigma: 1.5
          output_stride: 2
          loss_weight: 1.0
trainer_config:
  train_data_loader:
    batch_size: 4
    shuffle: true
    num_workers: 2
  val_data_loader:
    batch_size: 4
    num_workers: 2
  model_ckpt:
    save_top_k: 1
    save_last: true
  device: cuda
  trainer_devices: 1
  trainer_accelerator: gpu # TODO: redo device + trainer_accelerator!
  enable_progress_bar: false
  steps_per_epoch: 
  max_epochs: 10
  seed: 1000
  use_wandb: false
  save_ckpt: true
  save_ckpt_path: 'min_inst_centered'
  wandb:
    entity: 
    project: 'test_centroid_centered'
    name: 'fly_unet_centered'
    wandb_mode: ''
    api_key: ''
    log_params:
    - trainer_config.optimizer_name
    - trainer_config.optimizer.amsgrad
    - trainer_config.optimizer.lr
    - model_config.backbone_config.backbone_type
    - model_config.init_weights
  optimizer_name: Adam
  optimizer:
    lr: 0.0001
    amsgrad: false
  lr_scheduler:
    threshold: 1.0e-07
    cooldown: 3
    patience: 5
    factor: 0.5
    min_lr: 1.0e-08
  early_stopping:
    stop_training_on_plateau: True
    min_delta: 1.0e-08
    patience: 20