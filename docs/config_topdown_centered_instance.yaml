data_config:
  provider: LabelsReader
  train_labels_path: minimal_instance.pkg.slp
  val_labels_path: minimal_instance.pkg.slp
  user_instances_only: True
  chunk_size: 100
  preprocessing:
    max_width: 
    max_height: 
    scale: 1.0
    is_rgb: False
    crop_hw:
      - 160
      - 160
    min_crop_size:
  use_augmentations_train: true
  augmentation_config:
    geometric:
      rotation: 180.0
      scale: null
      translate_width: 0
      translate_height: 0
      affine_p: 0.5

model_config:
  init_weights: xavier
  pre_trained_weights:
  backbone_type: unet
  backbone_config:
      in_channels: 1
      kernel_size: 3
      filters: 16
      filters_rate: 2
      max_stride: 16
      convs_per_block: 2
      stacks: 1
      stem_stride: 
      middle_block: True
      up_interpolate: True
  
  # pre_trained_weights: ConvNeXt_Tiny_Weights
  # backbone_config:
  #   backbone_type: convnext
  #   backbone_config:
  #     in_channels: 1
  #     model_type: tiny
  #     arch: 
  #     kernel_size: 3
  #     filters_rate: 2
  #     convs_per_block: 2
  #     up_interpolate: True
  #     stem_patch_kernel: 4
  #     stem_patch_stride: 2

  # pre_trained_weights: Swin_T_Weights
  # backbone_config:
  #   backbone_type: swint
  #   backbone_config:
  #     in_channels: 1
  #     model_type: tiny
  #     arch: 
  #     patch_size: [4,4]
  #     window_size: [7,7]
  #     kernel_size: 3
  #     filters_rate: 2
  #     convs_per_block: 2
  #     up_interpolate: True
  #     stem_patch_stride: 2

  head_configs:
    single_instance:
    centroid:
    bottomup:
    centered_instance: 
      confmaps:
        part_names: None
        anchor_part: 0
        sigma: 1.5
        output_stride: 2
trainer_config:
  train_data_loader:
    batch_size: 4
    shuffle: true
    num_workers: 2
  val_data_loader:
    batch_size: 4
    num_workers: 2
  model_ckpt:
    save_top_k: 1
    save_last: true
  trainer_devices: 1
  trainer_accelerator: gpu # TODO: redo device + trainer_accelerator!
  enable_progress_bar: false
  steps_per_epoch: 
  max_epochs: 10
  seed: 1000
  use_wandb: false
  save_ckpt: true
  save_ckpt_path: 'min_inst_centered'
  bin_files_path:
  resume_ckpt_path:
  optimizer_name: Adam
  optimizer:
    lr: 0.0001
    amsgrad: false
  lr_scheduler:
    scheduler: ReduceLROnPlateau
    reduce_lr_on_plateau:
      threshold: 1.0e-07
      threshold_mode: abs
      cooldown: 3
      patience: 5
      factor: 0.5
      min_lr: 1.0e-08
  early_stopping:
    stop_training_on_plateau: True
    min_delta: 1.0e-08
    patience: 20